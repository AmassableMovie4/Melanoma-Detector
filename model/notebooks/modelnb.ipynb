{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962b0e62-9e53-4fc0-9f7e-0c99dbeeb772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /home/vuk/miniconda3/lib/python3.11/site-packages (1.6.6)\n",
      "Requirement already satisfied: six>=1.10 in /home/vuk/miniconda3/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /home/vuk/miniconda3/lib/python3.11/site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in /home/vuk/miniconda3/lib/python3.11/site-packages (from kaggle) (2.9.0)\n",
      "Requirement already satisfied: requests in /home/vuk/miniconda3/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/vuk/miniconda3/lib/python3.11/site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in /home/vuk/miniconda3/lib/python3.11/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /home/vuk/miniconda3/lib/python3.11/site-packages (from kaggle) (1.26.18)\n",
      "Requirement already satisfied: bleach in /home/vuk/miniconda3/lib/python3.11/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /home/vuk/miniconda3/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/vuk/miniconda3/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vuk/miniconda3/lib/python3.11/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vuk/miniconda3/lib/python3.11/site-packages (from requests->kaggle) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200362d8-a1db-4094-a732-c74e0c8794de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/vuk/miniconda3/lib/python3.11/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipywidgets) (8.22.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: decorator in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/vuk/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/vuk/miniconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/vuk/miniconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/vuk/miniconda3/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/vuk/miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "523379cc-59ef-4d84-9a23-fc7e3bdc24ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbfeba516944a36a47ecccdc1f6b380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "upload = widgets.FileUpload()\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0288ba2d-efe5-4ae8-bbec-5609ccbf0b98",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/root/.kaggle/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/root/.kaggle/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmv kaggle.json /root/.kaggle/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchmod 600 /root/.kaggle/kaggle.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/root/.kaggle/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Download your own kaggle.json and move it into home/urname or smth like that\n",
    "os.makedirs('/home/.kaggle/', exist_ok=True)\n",
    "!mv kaggle.json /root/.kaggle/\n",
    "\n",
    "\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18135728-d2e6-41c6-a6a2-eff9bb8609ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/vuk/miniconda3/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/vuk/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/vuk/miniconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/vuk/miniconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vuk/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vuk/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vuk/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vuk/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/vuk/miniconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/vuk/miniconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/vuk/miniconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe0a2ee6-eb50-4974-8a01-0668fe15cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2024-03-10 08:30:21.236419: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-10 08:30:23.655960: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-10 08:30:23.655987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-10 08:30:23.673945: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-10 08:30:23.715168: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-10 08:30:24.592579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
=======
      "2024-03-09 10:03:23.319880: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-09 10:03:25.152838: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-09 10:03:25.152931: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-09 10:03:25.687936: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-09 10:03:26.602758: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-09 10:03:44.034720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
>>>>>>> feat/dir-manipulation
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(101)\n",
    "import tensorflow \n",
    "tensorflow.random.set_seed(101)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Reshape, Conv2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcdd4e80-58ac-44ee-b6f3-7d607350e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "directory = '/home/vuk/Documents/ML Data/CDA1/' #input your path\n",
    "source_directory_1 = os.path.join(directory, 'HAM10000_images_part_1')\n",
    "source_directory_2 = os.path.join(directory, 'HAM10000_images_part_2')\n",
    "csv_location = os.path.join(directory, 'HAM10000_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75c4966d-f744-43ed-b7d5-57c166fd348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/vuk/Documents/ML Data/CDA1/HAM10000' already exists.\n"
     ]
    }
   ],
   "source": [
    "ham_directory = os.path.join(directory, 'HAM10000')\n",
    "if not os.path.exists(ham_directory):\n",
    "    os.makedirs(ham_directory)\n",
    "else:\n",
    "    print(f\"Directory '{ham_directory}' already exists.\")\n",
    "\n",
    "destination_directory = os.path.join(directory, 'HAM10000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e0c1406-2325-4923-b35b-fff0f1928cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images(src, dest):\n",
    "    for file in os.listdir(src):\n",
    "        file_path = os.path.join(src, file)\n",
    "        dest_path = os.path.join(dest, file)\n",
    "        shutil.move(file_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc60031-b955-46c1-ac1d-71b1b8ae0ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/vuk/Documents/ML Data/CDA1/HAM10000_images_part_1' does not exist or is empty.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/HAM10000_images_part_2' does not exist or is empty.\n"
     ]
    }
   ],
   "source": [
    "#Moves the images from ham1 and ham2 into ham folder\n",
    "if os.path.exists(source_directory_1) and os.listdir(source_directory_1):\n",
    "    move_images(source_directory_1, destination_directory)\n",
    "    shutil.rmtree(source_directory_1)\n",
    "else:\n",
    "    print(f\"Directory '{source_directory_1}' does not exist or is empty.\")\n",
    "\n",
    "if os.path.exists(source_directory_2) and os.listdir(source_directory_2):\n",
    "    move_images(source_directory_2, destination_directory)\n",
    "    shutil.rmtree(source_directory_2)\n",
    "else:\n",
    "    print(f\"Directory '{source_directory_2}' does not exist or is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20074efc-b49a-4086-a8aa-8bd63beba985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/vuk/Documents/ML Data/CDA1/test/nv' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/test/mel' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/test/bkl' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/test/bcc' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/test/akiec' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/test/vasc' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/test/df' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/train/nv' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/train/mel' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/train/bkl' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/train/bcc' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/train/akiec' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/train/vasc' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/train/df' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/validate/nv' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/validate/mel' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/validate/bkl' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/validate/bcc' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/validate/akiec' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/validate/vasc' already exists.\n",
      "Directory '/home/vuk/Documents/ML Data/CDA1/validate/df' already exists.\n"
     ]
    }
   ],
   "source": [
    "split_names = ['test', 'train', 'validate']\n",
    "\n",
    "for split_name in split_names:\n",
    "    split_path = os.path.join(directory, split_name)\n",
    "    for subfolder in ['nv', 'mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']:\n",
    "        subfolder_path = os.path.join(split_path, subfolder)\n",
    "        if not os.path.exists(subfolder_path):\n",
    "            os.makedirs(subfolder_path)\n",
    "        else:\n",
    "            print(f\"Directory '{subfolder_path}' already exists.\")\n",
    "base_dir = ham_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddf4a32b-67dd-4740-803c-c81509d69c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(csv_location)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "84a54aed-dced-43a8-9909-8de915c772bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lesion_id        0\n",
       "dx               0\n",
       "dx_type          0\n",
       "age             57\n",
       "sex              0\n",
       "localization     0\n",
       "duplicates       0\n",
       "train_or_val     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "88b8ae47-dee7-4eb7-a2a8-1dbb6e507b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['age'].fillna((df_data['age'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11f9d69d-96b6-4eab-8162-6167f40ae4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ISIC_0027419\n",
       "1        ISIC_0025030\n",
       "2        ISIC_0026769\n",
       "3        ISIC_0025661\n",
       "4        ISIC_0031633\n",
       "             ...     \n",
       "10010    ISIC_0033084\n",
       "10011    ISIC_0033550\n",
       "10012    ISIC_0033536\n",
       "10013    ISIC_0032854\n",
       "10014    ISIC_0032258\n",
       "Name: image_id, Length: 10015, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.reset_index(inplace=True)\n",
    "\n",
    "df_data['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4d7a4e8-cabb-44c9-bfd2-7e937877a429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>train_or_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  image_id  dx  dx_type  age  sex  localization  duplicates  \\\n",
       "0  HAM_0000001         1   1        1    1    1             1           1   \n",
       "1  HAM_0000003         1   1        1    1    1             1           1   \n",
       "2  HAM_0000004         1   1        1    1    1             1           1   \n",
       "3  HAM_0000007         1   1        1    1    1             1           1   \n",
       "4  HAM_0000008         1   1        1    1    1             1           1   \n",
       "\n",
       "   train_or_val  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = df_data.groupby('lesion_id').count()\n",
    "\n",
    "\n",
    "df = df[df['image_id'] == 1]\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5e78a81-17cd-426a-a4fd-4e84e1a82c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>train_or_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISIC_0027419</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>no_duplicates</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0025030</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>no_duplicates</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0026769</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>no_duplicates</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0025661</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>no_duplicates</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0031633</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>no_duplicates</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                lesion_id   dx dx_type   age   sex localization  \\\n",
       "image_id                                                          \n",
       "ISIC_0027419  HAM_0000118  bkl   histo  80.0  male        scalp   \n",
       "ISIC_0025030  HAM_0000118  bkl   histo  80.0  male        scalp   \n",
       "ISIC_0026769  HAM_0002730  bkl   histo  80.0  male        scalp   \n",
       "ISIC_0025661  HAM_0002730  bkl   histo  80.0  male        scalp   \n",
       "ISIC_0031633  HAM_0001466  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                 duplicates  train_or_val  \n",
       "image_id                                   \n",
       "ISIC_0027419  no_duplicates  ISIC_0027419  \n",
       "ISIC_0025030  no_duplicates  ISIC_0025030  \n",
       "ISIC_0026769  no_duplicates  ISIC_0026769  \n",
       "ISIC_0025661  no_duplicates  ISIC_0025661  \n",
       "ISIC_0031633  no_duplicates  ISIC_0031633  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identify_duplicates(x, unique_list):\n",
    "    if x in unique_list:\n",
    "        return 'no_duplicates'\n",
    "    else:\n",
    "        return 'has_duplicates'\n",
    "\n",
    "unique_list = df_data['lesion_id'].unique()\n",
    "\n",
    "df_data['duplicates'] = df_data['lesion_id'].apply(lambda x: identify_duplicates(x, unique_list))\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "99e832ed-dbc7-4da9-b683-ef08deacc94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_duplicates = df_data[df_data['duplicates'] == 'has_duplicates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "be339fd9-efd5-4544-b56e-a079942a3ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duplicates\n",
       "no_duplicates    10015\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eac92152-3e6d-47c2-848b-ec2c653a1c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 9)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = df_data[df_data['duplicates'] == 'no_duplicates']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d9d6eea8-c64f-477e-b1c9-17f25d7c4472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           image_id    lesion_id     dx dx_type   age     sex localization  \\\n",
      "0      ISIC_0027419  HAM_0000118    bkl   histo  80.0    male        scalp   \n",
      "1      ISIC_0025030  HAM_0000118    bkl   histo  80.0    male        scalp   \n",
      "2      ISIC_0026769  HAM_0002730    bkl   histo  80.0    male        scalp   \n",
      "3      ISIC_0025661  HAM_0002730    bkl   histo  80.0    male        scalp   \n",
      "4      ISIC_0031633  HAM_0001466    bkl   histo  75.0    male          ear   \n",
      "...             ...          ...    ...     ...   ...     ...          ...   \n",
      "10010  ISIC_0033084  HAM_0002867  akiec   histo  40.0    male      abdomen   \n",
      "10011  ISIC_0033550  HAM_0002867  akiec   histo  40.0    male      abdomen   \n",
      "10012  ISIC_0033536  HAM_0002867  akiec   histo  40.0    male      abdomen   \n",
      "10013  ISIC_0032854  HAM_0000239  akiec   histo  80.0    male         face   \n",
      "10014  ISIC_0032258  HAM_0003521    mel   histo  70.0  female         back   \n",
      "\n",
      "          duplicates  train_or_val  \n",
      "0      no_duplicates  ISIC_0027419  \n",
      "1      no_duplicates  ISIC_0025030  \n",
      "2      no_duplicates  ISIC_0026769  \n",
      "3      no_duplicates  ISIC_0025661  \n",
      "4      no_duplicates  ISIC_0031633  \n",
      "...              ...           ...  \n",
      "10010  no_duplicates  ISIC_0033084  \n",
      "10011  no_duplicates  ISIC_0033550  \n",
      "10012  no_duplicates  ISIC_0033536  \n",
      "10013  no_duplicates  ISIC_0032854  \n",
      "10014  no_duplicates  ISIC_0032258  \n",
      "\n",
      "[10015 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba619548-76c1-4939-b55e-7e25abbd0505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482     bkl\n",
      "7123     nv\n",
      "6581     nv\n",
      "6991     nv\n",
      "6333     nv\n",
      "       ... \n",
      "9564     nv\n",
      "4666     nv\n",
      "9382     nv\n",
      "4070     nv\n",
      "7570     nv\n",
      "Name: dx, Length: 6009, dtype: object\n",
      "          image_id    lesion_id    dx_type   age     sex     localization  \\\n",
      "482   ISIC_0030346  HAM_0005146      histo  60.0    male             face   \n",
      "7123  ISIC_0032007  HAM_0007477      histo  25.0    male             back   \n",
      "6581  ISIC_0030449  HAM_0007071  follow_up  35.0  female            trunk   \n",
      "6991  ISIC_0025812  HAM_0001767      histo  50.0  female  lower extremity   \n",
      "6333  ISIC_0027587  HAM_0003907  follow_up  60.0    male  upper extremity   \n",
      "...            ...          ...        ...   ...     ...              ...   \n",
      "9564  ISIC_0033467  HAM_0004197  consensus  40.0  female          unknown   \n",
      "4666  ISIC_0024648  HAM_0002304  follow_up  55.0  female  lower extremity   \n",
      "9382  ISIC_0025101  HAM_0005712  consensus   5.0  female             foot   \n",
      "4070  ISIC_0031320  HAM_0001206  follow_up  55.0    male          abdomen   \n",
      "7570  ISIC_0032615  HAM_0001808      histo  35.0  female             back   \n",
      "\n",
      "         duplicates  train_or_val  \n",
      "482   no_duplicates  ISIC_0030346  \n",
      "7123  no_duplicates  ISIC_0032007  \n",
      "6581  no_duplicates  ISIC_0030449  \n",
      "6991  no_duplicates  ISIC_0025812  \n",
      "6333  no_duplicates  ISIC_0027587  \n",
      "...             ...           ...  \n",
      "9564  no_duplicates  ISIC_0033467  \n",
      "4666  no_duplicates  ISIC_0024648  \n",
      "9382  no_duplicates  ISIC_0025101  \n",
      "4070  no_duplicates  ISIC_0031320  \n",
      "7570  no_duplicates  ISIC_0032615  \n",
      "\n",
      "[6009 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame containing both features and target variable\n",
    "# Extract the features (x) and target variable (y)\n",
    "x = df.drop(columns=['dx'])  # Exclude the target variable 'dx'\n",
    "y = df['dx']\n",
    "# Split the data into train-test-validate sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Check the shape of y_val\n",
    "print(y_train)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2649bcfe-bf45-4045-aec8-3dc9340deeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           image_id    lesion_id dx_type   age     sex localization  \\\n",
      "0      ISIC_0027419  HAM_0000118   histo  80.0    male        scalp   \n",
      "1      ISIC_0025030  HAM_0000118   histo  80.0    male        scalp   \n",
      "2      ISIC_0026769  HAM_0002730   histo  80.0    male        scalp   \n",
      "3      ISIC_0025661  HAM_0002730   histo  80.0    male        scalp   \n",
      "4      ISIC_0031633  HAM_0001466   histo  75.0    male          ear   \n",
      "...             ...          ...     ...   ...     ...          ...   \n",
      "10010  ISIC_0033084  HAM_0002867   histo  40.0    male      abdomen   \n",
      "10011  ISIC_0033550  HAM_0002867   histo  40.0    male      abdomen   \n",
      "10012  ISIC_0033536  HAM_0002867   histo  40.0    male      abdomen   \n",
      "10013  ISIC_0032854  HAM_0000239   histo  80.0    male         face   \n",
      "10014  ISIC_0032258  HAM_0003521   histo  70.0  female         back   \n",
      "\n",
      "          duplicates  train_or_val  \n",
      "0      no_duplicates  ISIC_0027419  \n",
      "1      no_duplicates  ISIC_0025030  \n",
      "2      no_duplicates  ISIC_0026769  \n",
      "3      no_duplicates  ISIC_0025661  \n",
      "4      no_duplicates  ISIC_0031633  \n",
      "...              ...           ...  \n",
      "10010  no_duplicates  ISIC_0033084  \n",
      "10011  no_duplicates  ISIC_0033550  \n",
      "10012  no_duplicates  ISIC_0033536  \n",
      "10013  no_duplicates  ISIC_0032854  \n",
      "10014  no_duplicates  ISIC_0032258  \n",
      "\n",
      "[10015 rows x 8 columns] 0          bkl\n",
      "1          bkl\n",
      "2          bkl\n",
      "3          bkl\n",
      "4          bkl\n",
      "         ...  \n",
      "10010    akiec\n",
      "10011    akiec\n",
      "10012    akiec\n",
      "10013    akiec\n",
      "10014      mel\n",
      "Name: dx, Length: 10015, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d50aaca-3cb8-49f8-acef-447ab68f188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIBIDI TOILETVS CREEPER\n"
     ]
    }
   ],
   "source": [
    "x_train_image_ids = set(x_train['image_id'])\n",
    "x_test_image_ids = set(x_test['image_id'])\n",
    "x_val_image_ids = set(x_val['image_id'])\n",
    "\n",
    "\n",
    "train_test_overlap = x_train_image_ids.intersection(x_test_image_ids)\n",
    "train_val_overlap = x_train_image_ids.intersection(x_val_image_ids)\n",
    "test_val_overlap = x_test_image_ids.intersection(x_val_image_ids)\n",
    "\n",
    "if train_test_overlap:\n",
    "    print(\"Images present in both training and testing sets:\", train_test_overlap)\n",
    "if train_val_overlap:\n",
    "    print(\"Images present in both training and validation sets:\", train_val_overlap)\n",
    "if test_val_overlap:\n",
    "    print(\"Images present in both testing and validation sets:\", test_val_overlap)\n",
    "else:\n",
    "    print(\"SKIBIDI TOILETVS CREEPER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa2b4b40-60ae-458a-90df-3e99bca5e465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dx\n",
       "nv       4050\n",
       "mel       657\n",
       "bkl       628\n",
       "bcc       310\n",
       "akiec     201\n",
       "vasc       94\n",
       "df         69\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "52cfd448-9439-4089-b6f7-2c16121d140b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dx\n",
       "nv       1317\n",
       "bkl       243\n",
       "mel       230\n",
       "bcc       111\n",
       "akiec      57\n",
       "vasc       27\n",
       "df         18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7a33d5fe-b79a-4cd7-acf2-1c94c98e5b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1617    ISIC_0033272\n",
       "8128    ISIC_0031923\n",
       "2168    ISIC_0026652\n",
       "1090    ISIC_0030583\n",
       "7754    ISIC_0034010\n",
       "            ...     \n",
       "1770    ISIC_0030238\n",
       "1888    ISIC_0034317\n",
       "2020    ISIC_0032245\n",
       "1642    ISIC_0033779\n",
       "4823    ISIC_0029949\n",
       "Name: image_id, Length: 2003, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()\n",
    "x_test['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b214d142-5594-473c-9bd6-c71b6444950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = list(x_train['image_id'])\n",
    "test_list = list(x_test['image_id'])\n",
    "val_list = list(x_val['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f22a32a9-bf68-4a1b-8e1f-0ba368c90dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294fbdb-12e7-428d-bf44-cfe8f6230d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of images in each of the two folders\n",
    "\n",
    "split_names = ['train_list','test_list','val_list']\n",
    "\n",
    "folder = os.listdir('HAM10000')\n",
    "\n",
    "# Transfer the train images\n",
    "for split_option in split_names:\n",
    "    for image in split_option:\n",
    "        \n",
    "        fname = image + '.jpg'\n",
    "        label = df_data.loc[image,'dx']\n",
    "        \n",
    "        if fname in folder:\n",
    "            # source path to image\n",
    "            src = os.path.join(folder, fname)\n",
    "            # destination path to image\n",
    "            dst = os.path.join(split_option, label, fname)\n",
    "            # copy the image from the source to the destination\n",
    "            shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc10149-4f3b-4bf7-b7b6-70b1981e33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(os.listdir('base_dir/train_dir/nv')))\n",
    "print(len(os.listdir('base_dir/train_dir/mel')))\n",
    "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/train_dir/df')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a79d8-6f92-4541-b66d-aa23a36da39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/nv')))\n",
    "print(len(os.listdir('base_dir/val_dir/mel')))\n",
    "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/val_dir/df')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45946c-6c62-4b6d-9f23-160a65b2b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we are not augmenting class 'nv'\n",
    "class_list = ['mel','bkl','bcc','akiec','vasc','df']\n",
    "\n",
    "for item in class_list:\n",
    "    \n",
    "    # We are creating temporary directories here because we delete these directories later\n",
    "    # create a base dir\n",
    "    aug_dir = 'aug_dir'\n",
    "    os.mkdir(aug_dir)\n",
    "    # create a dir within the base dir to store images of the same class\n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "    # Choose a class\n",
    "    img_class = item\n",
    "\n",
    "    # list all images in that directory\n",
    "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
    "\n",
    "    # Copy images from the class train dir to the img_dir e.g. class 'mel'\n",
    "    for fname in img_list:\n",
    "            # source path to image\n",
    "            src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
    "            # destination path to image\n",
    "            dst = os.path.join(img_dir, fname)\n",
    "            # copy the image from the source to the destination\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "    # point to a dir containing the images and not to the images themselves\n",
    "    path = aug_dir\n",
    "    save_path = 'base_dir/train_dir/' + img_class\n",
    "\n",
    "    # Create a data generator\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        #brightness_range=(0.9,1.1),\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(path,\n",
    "                                           save_to_dir=save_path,\n",
    "                                           save_format='jpg',\n",
    "                                                    target_size=(125,100),\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    # Generate the augmented images and add them to the training folders\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    num_aug_images_wanted = 6000 # total number of images we want to have in each class\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n",
    "\n",
    "    # run the generator and create about 6000 augmented images\n",
    "    for i in range(0,num_batches):\n",
    "\n",
    "        imgs, labels = next(aug_datagen)\n",
    "        \n",
    "    # delete temporary directory with the raw image files\n",
    "    shutil.rmtree('aug_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf2447-7a2f-4583-a339-f747bdbdff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many train images we now have in each folder.\n",
    "# This is the original images plus the augmented images.\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/nv')))\n",
    "print(len(os.listdir('base_dir/train_dir/mel')))\n",
    "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/train_dir/df')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e6093-11fd-4b90-8626-c92c4edf5037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many val images we have in each folder.\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/nv')))\n",
    "print(len(os.listdir('base_dir/val_dir/mel')))\n",
    "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/val_dir/df')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d88da-bdfe-42a8-a15f-23ca394e5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots images with labels within jupyter notebook\n",
    "# source: https://github.com/smileservices/keras_utils/blob/master/utils.py\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "        \n",
    "plots(imgs, titles=None) # titles=labels will display the image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58a78f-5b01-427b-a4f7-f7f08e320f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "    tensorflow.keras.applications.mobilenet.preprocess_input)\n",
    "\n",
    "train_batches = datagen.flow_from_directory(train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=train_batch_size)\n",
    "\n",
    "valid_batches = datagen.flow_from_directory(valid_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=val_batch_size)\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled bug?\n",
    "test_batches = datagen.flow_from_directory(train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 117,
>>>>>>> feat/dir-manipulation
   "id": "62c00c4b-e16d-4512-8a55-85d61d01afc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2024-03-10 08:33:04.102445: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-10 08:33:04.447238: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
=======
      "2024-03-09 11:21:55.204387: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-09 11:21:55.653905: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
>>>>>>> feat/dir-manipulation
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
      "17225924/17225924 [==============================] - 2s 0us/step\n"
=======
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
      "14536120/14536120 [==============================] - 2s 0us/step\n"
>>>>>>> feat/dir-manipulation
     ]
    }
   ],
   "source": [
    "mobile = tensorflow.keras.applications.mobilenet_v2.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6174c8aa-5bbe-47bb-acd9-8e87312e4197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizati  (None, 112, 112, 32)      128       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D  (None, 112, 112, 32)      288       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormali  (None, 112, 112, 32)      128       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormali  (None, 112, 112, 64)      256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D  (None, 56, 56, 64)        576       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormali  (None, 56, 56, 64)        256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D  (None, 56, 56, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D  (None, 28, 28, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormali  (None, 28, 28, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D  (None, 28, 28, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D  (None, 14, 14, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormali  (None, 14, 14, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D  (None, 15, 15, 512)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2  (None, 7, 7, 512)         4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormal  (None, 7, 7, 512)         2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2  (None, 7, 7, 1024)        9216      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1, 1, 1024)        0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " conv_preds (Conv2D)         (None, 1, 1, 1000)        1025000   \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1000)              0         \n",
      "                                                                 \n",
      " predictions (Activation)    (None, 1000)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4253864 (16.23 MB)\n",
      "Trainable params: 4231976 (16.14 MB)\n",
      "Non-trainable params: 21888 (85.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile.summary() #left for someone brave enough..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b67c36-08a6-4335-a938-08a41d263c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mobile.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50894b4-c5a2-422c-997b-fbc5ad849cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE MODEL ARCHITECTURE\n",
    "\n",
    "# Exclude the last 5 layers of the above model.\n",
    "# This will include all layers up to and including global_average_pooling2d_1\n",
    "\n",
    "\n",
    "# Create a new dense layer for predictions\n",
    "# 7 corresponds to the number of classes\n",
    "x = mobile.get_layer('global_average_pooling2d').output\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(7, (1,1), padding='same')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "           \n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "# inputs=mobile.input selects the input layer, outputs=predictions refers to the\n",
    "# dense layer we created above.\n",
    "\n",
    "model = Model(inputs=mobile.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527693d-bab2-48aa-92e9-6f13ed459084",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cedfd9-043c-431d-8f5c-3a2f2bf7fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to choose how many layers we actually want to be trained.\n",
    "\n",
    "# Here we are freezing the weights of all layers except the\n",
    "# last 23 layers in the new model.\n",
    "# The last 23 layers of the model will be trained.\n",
    "\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445871cb-1802-46c4-98da-f0e424268494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Top2 and Top3 Accuracy\n",
    "\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd6991-f52f-4907-9fcd-19a420cac622",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(learning_rate=0.01), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb844090-0f7a-4539-b71f-2bc4a06cffd5",
   "metadata": {},
   "source": [
    "print(valid_batches.class_indices)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d3ba0f1-e7c8-4913-a8dc-008a4e140088",
   "metadata": {},
   "source": [
    "class_weights={\n",
    "    0: 1.0, # akiec\n",
    "    1: 1.0, # bcc\n",
    "    2: 1.0, # bkl\n",
    "    3: 1.0, # df\n",
    "    4: 3.0, # mel \n",
    "    5: 1.0, # nv\n",
    "    6: 1.0, # vasc\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d21b9f3-9133-47e3-920e-6568e95e0896",
   "metadata": {},
   "source": [
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit(train_batches, steps_per_epoch=train_steps, \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=valid_batches,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=30, verbose=1,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "806abc8b-18f6-4320-adad-39fe065058c6",
   "metadata": {},
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4160c73e-5372-4817-adcc-dd581c33e7cc",
   "metadata": {},
   "source": [
    "# Here the the last epoch will be used.\n",
    "\n",
    "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
    "model.evaluate(test_batches, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_cat_acc:', val_cat_acc)\n",
    "print('val_top_2_acc:', val_top_2_acc)\n",
    "print('val_top_3_acc:', val_top_3_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7173bf66-a8b4-4b30-8279-91e94afdeb31",
   "metadata": {},
   "source": [
    "# Here the best epoch will be used.\n",
    "\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
    "model.evaluate(test_batches, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_cat_acc:', val_cat_acc)\n",
    "print('val_top_2_acc:', val_top_2_acc)\n",
    "print('val_top_3_acc:', val_top_3_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fca2e33-7dab-44d0-9993-2a6c68d3065e",
   "metadata": {},
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_top2_acc = history.history['top_2_accuracy']\n",
    "val_top2_acc = history.history['val_top_2_accuracy']\n",
    "train_top3_acc = history.history['top_3_accuracy']\n",
    "val_top3_acc = history.history['val_top_3_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot(epochs, train_top2_acc, 'bo', label='Training top2 acc')\n",
    "plt.plot(epochs, val_top2_acc, 'b', label='Validation top2 acc')\n",
    "plt.title('Training and validation top2 accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_top3_acc, 'bo', label='Training top3 acc')\n",
    "plt.plot(epochs, val_top3_acc, 'b', label='Validation top3 acc')\n",
    "plt.title('Training and validation top3 accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be161606-9497-4870-8dc5-524146e3a700",
   "metadata": {},
   "source": [
    "test_labels = test_batches.classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb1930ee-2b78-4155-9179-88aa15beea45",
   "metadata": {},
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e735105-4fa6-4936-b238-a859bc664cb2",
   "metadata": {},
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77c39ffd-9683-459c-8c64-f144ccc12a8c",
   "metadata": {},
   "source": [
    "predictions = model.predict(test_batches, steps=len(df_val), verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b7c2e92-e298-4466-96c1-356d68343303",
   "metadata": {},
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "791d91de-07ba-4839-b2cd-60e6d0dedddf",
   "metadata": {},
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "621b346f-eee5-4598-ab2c-39f4aff13ab0",
   "metadata": {},
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7eaa78a-97fa-4827-bd99-2d04d4b454b3",
   "metadata": {},
   "source": [
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35457a3a-4308-40d3-bc6e-ccbd23feba92",
   "metadata": {},
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc6559ef-1d37-42ce-bf3b-c2adc3d0dd84",
   "metadata": {},
   "source": [
    "cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n",
    "\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67d7f936-93f6-48e2-9ae6-0030dc98ca4b",
   "metadata": {},
   "source": [
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the labels of the test images.\n",
    "y_true = test_batches.classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffb68cd2-f36f-4c7a-94e0-b26bb40c1965",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_true, y_pred, target_names=cm_plot_labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9137939-e427-4185-9d90-209075136138",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9dcbdc-3849-407f-81ec-ae755b940f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ef9b2-ca9f-4f67-91df-55191d93c476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
